\guidelinesubsubsection{Rationale}

Transparency about LLM involvement is a prerequisite for informed assessment of a study's scope, limitations, and potential biases.
Without explicit disclosure, readers cannot evaluate how the LLM's characteristics may have influenced the research process or its outcomes.

\guidelinesubsubsection{Recommendations}

When conducting any kind of empirical study involving LLMs, researchers \must clearly declare that an LLM was used (see \scope for what we consider relevant research support).
This \should be done in a suitable section of the \paper, for example, in the introduction or research methods section.
For authoring scientific articles, this transparency is, for example, required by the ACM Policy on Authorship: \enq{The use of generative AI tools and technologies to create content is permitted but must be fully disclosed in the Work}~\cite{ACM2023}.

Beyond generic declarations, researchers \should report the exact purpose of using an LLM in a study, the tasks it was used to automate, and the expected benefits in the \paper.
A sufficient declaration specifies not only \emph{that} an LLM was used, but also \emph{which} LLM (name and version), \emph{how} it was used (e.g., as an annotator, code generator, or judge), and \emph{where} in the research process it was employed (e.g., data collection, analysis, or synthesis).

When the LLM plays a central role in the study (e.g., as the main tool being evaluated or as a core component of the research method), the declaration \should be prominent and detailed, appearing in the methodology section with cross-references to the specific guidelines that apply (e.g., Sections \modelversion, \toolarchitecture, and \prompts).
When the LLM's role is more tangential (e.g., used for a single preprocessing step), a brief but explicit statement in the methodology or acknowledgments section is sufficient.
In either case, the disclosure \must be specific enough for readers to assess how the LLM's involvement may affect the study's validity and reproducibility.
% Related paper:
% Artificial intelligenceâ€‘assisted academic writing: recommendations for ethical use
% https://doi.org/10.1186/s41077-025-00350-6

\guidelinesubsubsection{Example(s)}

The \emph{ACM Policy on Authorship}~\cite{ACM2023} suggests disclosing GenAI usage in the acknowledgments section of the \paper, advising to ``err on the side of caution, and include a disclosure in the acknowledgments section of the Work'' when uncertain about the need~\cite{ACM2023}.
For double-blind review, researchers can add a temporary ``AI Disclosure'' section where the acknowledgments would appear.
An example of an LLM disclosure beyond writing support can be found in a recent paper by \citeauthor{DBLP:conf/re/LubosFTGMEL24}~\cite{DBLP:conf/re/LubosFTGMEL24}, in which they write in the methodology section:

\begin{quote}
\it
``We conducted an LLM-based evaluation of requirements utilizing the Llama 2 language model with 70 billion parameters, fine-tuned to complete chat responses...''
\end{quote}

\guidelinesubsubsection{Benefits}

Transparency in the use of LLMs helps other researchers understand the context and scope of the study, facilitating better interpretation and comparison of the results.
Beyond this declaration, we recommend researchers to be explicit about the LLM version they used (see \modelversion) and the LLM's exact role.

\guidelinesubsubsection{Challenges}

Declaring LLM usage requires only a brief statement and no additional experiments, making compliance straightforward.
One challenge might be authors' reluctance to disclose LLM usage for valid use cases, because they fear that AI-generated content makes reviewers think that the authors' work is less original.
In fact, there is evidence suggesting that AI disclosure can negatively affect trust in authors~\cite{SCHILKE2025104405}.
However, the \emph{ACM Policy on Authorship} is very clear in that any use of GenAI tools to create content \must be disclosed.
Our guidelines focus on research support beyond proof-reading and writing support (see \scope), but the threshold of what must be declared continues to evolve as organizations such as the ACM update their authorship policies.

\guidelinesubsubsection{Study Types}

Researchers \must follow this guideline for all study types.
The specific focus of the declaration varies by study type.
For \annotators, \judges, \synthesis, and \subjects, researchers \must declare the specific role assigned to the LLM (e.g., annotator, judge, synthesizer, or simulated participant).
For \llmusage, researchers \must clarify which LLM(s) the observed participants used and under which conditions.
For \newtools, researchers \must declare the LLM's role within the tool architecture and its contribution to the tool's functionality.
For \benchmarkingtasks, researchers \must declare which LLMs were benchmarked and for which tasks.

\guidelinesubsubsection{Advice for Reviewers}

The most common problem with disclosure is incompleteness or vagueness about how the LLM was used. If the paper says ``we used LLM X to help with task Y'' without specifying how, reviewers should request clarification. Such requests are typically minor revisions unless the missing details may reveal methodological problems.

Using an LLM as a copyeditor becomes problematic when authors do not or cannot take responsibility for the resulting text. If a reviewer finds clear evidence that LLM-generated text was not carefully reviewed (e.g., text like ``As a Large Language Model, I...''), this may warrant rejection. If a reviewer suspects an author \textit{cannot} take responsibility for AI-generated text, they should raise the concern with their editor or program chair. Due process requires that authors not be accused of misconduct without clear evidence.

If undisclosed LLM use is suspected, the reviewer should similarly consult their editor or program chair. When the evidence is conclusive, the key question is the degree to which undisclosed use affects the study's contribution, ranging from negligible (e.g., word choice in a single sentence) to severe (e.g., generating ostensibly empirical data or statistical analyses).

\guidelinesubsubsection{See Also}
\begin{itemize}[label=$\rightarrow$]
    \item Section~\modelversion: model version and configuration details.
    \item Section~\toolarchitecture: system-level role documentation.
    \item Section~\prompts: prompt documentation and interaction logs.
\end{itemize}