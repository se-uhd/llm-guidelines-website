\guidelinesubsubsection{Recommendations}

When conducting any kind of empirical study involving LLMs, researchers \must clearly declare that an LLM was used (see \scope for what we consider relevant research support).
This \should be done in a suitable section of the \paper, for example, in the introduction or research methods section.
For authoring scientific articles, this transparency is, for example, required by the ACM Policy on Authorship: \enq{The use of generative AI tools and technologies to create content is permitted but must be fully disclosed in the Work}~\cite{ACM2023}.
Beyond generic authorship declarations and declarations that LLMs were used as part of the research process, researchers \should report the exact purpose of using an LLM in a study, the tasks it was used to automate, and the expected benefits in the \paper.
% Related paper:
% Artificial intelligenceâ€‘assisted academic writing: recommendations for ethical use
% https://doi.org/10.1186/s41077-025-00350-6

\guidelinesubsubsection{Example(s)}

The \emph{ACM Policy on Authorship} suggests to disclose the usage of GenAI tools in the acknowledgments section of the \paper, for example: \emph{``ChatGPT was utilized to generate sections of this Work, including text, tables, graphs, code, data, citations''}~\cite{ACM2023}. 
Similarly, the acknowledgments section could also be used to disclose GenAI usage for other aspects of the research, if not explicitly described in other sections.
The ACM policy further suggests: \emph{``If you are uncertain about the need to disclose the use of a particular tool, err on the side of caution, and include a disclosure in the acknowledgments section of the Work''}~\cite{ACM2023}.
For double-blind review, during which the acknowledgments section is usually hidden, researchers can add a temporary ``AI Disclosure'' section in the same place the acknowledgments section would appear. 
An example of an LLM disclosure beyond writing support can be found in a recent paper by \citeauthor{DBLP:conf/re/LubosFTGMEL24}~\cite{DBLP:conf/re/LubosFTGMEL24}, in which they write in the methodology section:

\begin{quote}
\small
\it
``We conducted an LLM-based evaluation of requirements utilizing the Llama 2 language model with 70 billion parameters, fine-tuned to complete chat responses...''
\end{quote}

\guidelinesubsubsection{Advantages}

Transparency in the use of LLMs helps other researchers understand the context and scope of the study, facilitating better interpretation and comparison of the results.
Beyond this declaration, we recommend researchers to be explicit about the LLM version they used (see Section \modelversion) and the LLM's exact role (see Section \toolarchitecture).

\guidelinesubsubsection{Challenges}

In general, we expect following our recommendations to be straightforward.
One challenge might be authors' reluctance to disclose LLM usage for valid use cases because they fear that AI-generated content makes reviewers think that the authors' work is less original.
However, the \emph{ACM Policy on Authorship} is very clear in that any use of GenAI tools to create content \must be disclosed.
Before the introduction of LLMs, human proof-reading was possible and allowed and was not required to be declared.
Our guidelines focus on research support beyond proof-reading and writing support (see \scope).
However, over time, the threshold of what must be declared and what not will most likely evolve.

\guidelinesubsubsection{Study Types}

Researchers \must follow this guideline for all study types.
