\guidelinesubsubsection{Rationale}

When using LLMs for empirical studies in SE, researchers face unique challenges and potential limitations that can influence the validity, reliability, and reproducibility of their findings~\cite{sallou2024breaking}.
It is important to openly discuss these limitations and explain how their impact was mitigated.
These limitations are relative to current LLM capabilities and tool architectures; speculating about future improvements is beyond the scope of a paper's limitation section.
Nevertheless, risk management and threat mitigation should be planned during study design, not as an afterthought.

\guidelinesubsubsection{Recommendations}
Researchers \must make every effort to present the limitations of their work clearly without defensiveness or obfuscation. These limitations may concern diverse topics including generalizability, internal validity (e.g. data leakage), reliability (i.e. non-determinism), and reproducibility (e.g. resource requirements). 
When deterministic reproducibility is structurally unattainable (e.g., SaaS-based models with opaque versioning), researchers \should adopt trustworthiness criteria from qualitative research to substantiate dependability and confirmability of findings.
LLM-based studies may involve many kinds of generalization including the following:
\begin{enumerate}
    \item From tested LLMs to others; that is, do the performance characteristics of the LLM(s) studied generalize to LLM(s) not included in the study.
    \item From tested configurations to others; that is, how sensitive are the results to the specific configuration(s) of the LLM under test. 
    \item From research to practice; for instance, just because researchers can get a certain level of code generation performance under ideal conditions does not mean software developers, given the same tools, will get similar results without having the researchers present to show them exactly what to do. 
    \item From a sample of people (e.g. human validators; human participants) to a larger population of people.
    \item From one time period to another; i.e., does the same LLM, or other versions of the same LLM, produce similar results at a different point in time?
\end{enumerate}

The following concerns present an overview that has to be tailored to the individual study context. This section does not repeat requirements from other recommendations.

\paragraph{Internal Validity:}
The primary threats to internal validity are:
\begin{itemize}
	\item Data leakage and contamination, including inter-dataset duplication, potentially resulting in a training–evaluation overlaps, leading to overly optimistic evaluation results.
	\item Unintended inclusion of evaluation data in model-improvement pipelines, contributing to data leakage. This is especially relevant for longitudinal studies including LLMs.
	\item Incomplete architecture, prompt, or pipeline reporting, posing hidden confounding factors.
\end{itemize}

Inter-dataset duplication is prevalent in SE, particularly for code-related benchmarks. As transparency on training data is limited for LLMs, researchers \must discuss potential data leakage effects and their impact on results.

\paragraph{Construct Validity:}
The primary threats to construct validity are:
\begin{itemize}
	\item Metric–construct mismatch (e.g., BLEU/ROUGE vs. functional correctness). More traditional metrics might not capture all relevant SE-specific aspects.
	\item Over-reliance on benchmark-specific metrics. Optimizing for a single benchmark might result in dataset-specific heuristics rather than the intended construct, overstating real-world utility.
	\item Benchmark scope limitations. Benchmarks commonly ignore runtime behaviors, security implications, readability, testability, and maintainability, yielding results that may not transfer to realistic development settings.
\end{itemize}

If constructs are based on subjective interpretations, purely automated metrics are insufficient. Researchers \must discuss how they ensured quality of subjective results, similarly to qualitative research.

\paragraph{External Validity:}
The primary threats to external validity are:
\begin{itemize}
    \item Cross-model transfer limitations. Results obtained with one LLM (or family of LLMs) may not generalize to others due to differences in training data, architecture, and capabilities.
    \item Tool-architecture specificity. Tools built around a specific LLM's API or capabilities may not transfer to other models without significant re-engineering.
    \item Limited domain coverage. Studies often focus on a narrow set of programming languages, task types, or application domains, limiting generalizability to other SE contexts.
    \item Limited participant diversity. Study participants (e.g., human validators, developers) may not represent the broader population in terms of expertise, geographic location, or cultural background.
    \item Cross-time instability (model evolution). Performance of proprietary models can change over time, leading to non-generalizable study outcomes~\cite{DBLP:journals/corr/abs-2307-09009, doi:10.1148/radiol.232411}.
\end{itemize}

Generalizability is particularly critical for proprietary and non-deterministic systems whose behavior is subject to drift (i.e., silent changes in model output over time)~\cite{DBLP:journals/corr/abs-2307-09009}. The limitations and mitigations used for external validity \must be discussed by the researchers.

\paragraph{Reliability \& Reproducibility:}
The primary threats to reliability and reproducibility are:
\begin{itemize}
    \item Non-deterministic outputs. Identical prompts and configurations can yield different outputs across runs due to factors such as floating-point arithmetic, batching, and stochastic decoding strategies.
    \item Infrastructure dependence. Results may vary depending on the hardware, software stack, and hosting environment used, making exact replication challenging across different infrastructure setups.
    \item Resource inequality preventing replication. LLM research is resource-intensive and hence remains predominantly in the domain of private companies or well-funded research institutions~\cite{schwartz2020green, ahmed2023industry}, excluding researchers from under-resourced institutions.
\end{itemize}

Researchers \must discuss the measures taken to increase reliability and reproducibility.
However, non-deterministic reproducibility is not inherently disqualifying. Qualitative traditions such as ethnography, grounded theory, and action research ensure trustworthiness through \emph{credibility}, \emph{transferability}, \emph{dependability}, and \emph{confirmability}~\cite{guba1981criteria}.
SaaS-based LLM research faces analogous conditions, as providers frequently deprecate model versions without guaranteeing stable behavior.

\paragraph{Ethical \& Regulatory Boundaries:}
The primary concerns for ethical and regulatory matters are:
\begin{itemize}
    \item Use of sensitive or proprietary data. Studies involving proprietary code, confidential business data, or personally identifiable information may face restrictions on data sharing that limit reproducibility.
    \item Jurisdictional obligations. Data protection regulations (e.g., GDPR, CCPA) and institutional policies may impose constraints on data collection, processing, and sharing in LLM-based studies.
    \item Implicit model bias. Especially for qualitative research LLM might \enq{reinforce dominant paradigms and biases} and \enq{identify, replicate and reinforce dominant language and patterns}~\cite{jowsey2025reject}.
\end{itemize}

Studies involving sensitive data \must discuss data governance mechanisms tailored towards LLM environments, compliant with applicable juristical obligations. If applicable, researchers \should discuss how model biases potentially impact the study outcomes and how those biases were evaluated.

\paragraph{Environmental \& Sustainability Constraints:}
\begin{itemize}
    \item Energy consumption. With growing model size, the environmental impact of experiments with LLMs increases. Considering the environmental impact in the study design is important given the substantial energy costs of LLM experiments~\cite{strubell2019energy}.
    \item Trade-off between repetition and sustainability. Increased reliability through repetition and the aim of cautious energy consumption pose an inherent tension field to navigate during the study design.
\end{itemize}

The study findings \should be discussed in the context of the resource-intensiveness of LLMs to justify the increased resource consumption over traditional approaches.

\paragraph{Mitigation Strategies}
The following mitigation strategies can help address the threats described above, depending on the study scope and feasibility.

\begin{itemize}
    \item \emph{Replication Packages} covering prompt and architecture specifications, model outputs, and representative examples for partial replicability, accompanied by an implementation using an open model for long-term stability.
    \item \emph{Human Validation} of subjective constructs, following quality criteria known from qualitative research.
    \item \emph{Longitudinal Re-Runs} to repeat experiments with LLMs over time, complemented by statistical analyses.
    \item \emph{Methodological Trustworthiness Measures.} Researchers \should consider triangulation, reflexivity, audit trails, and peer debriefing as complementary measures when deterministic reproduction is structurally impossible.
    \item \emph{Triangulation} via multiple models (e.g., proprietary and open models), multiple independent datasets, and multiple complementary metrics.
    \item \emph{Cost Accounting} through reporting of input/output tokens, token and service costs, or hardware specifications.
    \item \emph{Energy Preservation} by selecting smaller or newer less resource-intensive models and employing techniques such as input/output token reduction, model pruning, quantization, or knowledge distillation~\cite{mitu2024hidden} where feasible. Carbon footprint estimation is desirable, but still difficult.
    \item \emph{Ethical and Regulatory Considerations} through data governance mechanisms, ethical reviews, and bias assessment procedures.
    \item \emph{Sensitivity Analysis} through variation of LLM configurations, prompts, architecture decisions, datasets, and if applicable human participant backgrounds.
\end{itemize}

\guidelinesubsubsection{Study Types}

Researchers \must follow this guideline for all study types. Transparently reporting limitations and mitigations is a universal requirement, but specific concerns vary by study type.
For \annotators, researchers \must discuss potential biases in label assignment, label reliability limitations, and sensitivity of annotations to prompt wording and model choice.
For \judges, researchers \must address measurement validity concerns, known biases such as position bias or verbosity bias, and the extent to which LLM judgments align with human expert assessments.
For \synthesis, researchers \must discuss the risk of contextual misinterpretation, potential loss of nuance in summarized or aggregated outputs, and reflexivity limitations inherent in using an LLM for qualitative interpretation.
For \subjects, researchers \must discuss the fundamental inability of LLMs to truly simulate human behavior, the risk of stereotype amplification, and the limited ecological validity of simulated responses.
For \llmusage, researchers \must discuss generalizability constraints across different tools and user populations, and acknowledge how observed usage patterns may not transfer to other contexts.
For \newtools, researchers \must discuss replicability constraints arising from dependencies on commercial models, the impact of model updates on tool behavior, and limitations of the evaluation setup.
For \benchmarkingtasks, researchers \must discuss potential data contamination, benchmark scope limitations, and the extent to which benchmark performance generalizes to real-world tasks.

%% Suggestion: Consider softening "perfunctory or defensive" → "formulaic or insufficiently engaged with the study's specific threats".
%% Suggestion: Consider adding a bridging sentence connecting back to the "request additions first" principle used in other guidelines.
\guidelinesubsubsection{Advice for Reviewers}

Reviewers should verify that the limitation section is comprehensive and appropriate for the specific study type, checking that:
(1) limitations address the specific threats relevant to the study type (e.g., label reliability for annotation studies, simulation fidelity for studies using LLMs as subjects);
(2) mitigations are concrete and correspond to identified limitations rather than being generic statements;
(3) the impact of LLM non-determinism on findings is discussed;
(4) generalizability constraints---across models, configurations, time periods, and populations---are acknowledged.
When important limitations are missing, reviewers should request they be added. The absence of a limitation section, or one that is formulaic or insufficiently specific, is a more serious concern than any individual missing limitation and may warrant a major revision.

\guidelinesubsubsection{See Also}
\begin{itemize}[label=$\rightarrow$]
    \item Section~\modelversion: model configuration, cost accounting, and sensitivity analysis.
    \item Section~\toolarchitecture: architecture-level triangulation and sensitivity analysis.
    \item Section~\prompts: prompt reporting, audit trails, and longitudinal re-runs.
    \item Section~\benchmarksmetrics: metric selection and benchmark limitations.
    \item Section~\humanvalidation: human validation of subjective constructs.
\end{itemize}