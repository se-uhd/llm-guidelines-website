\studytypesubsection{Studying LLM Usage in Software Engineering}
\label{sec:studying-llm-usage-in-software-engineering}

\studytypeparagraph{Description}

Studying how software engineers use LLMs is crucial to understand the current state of practice in SE.
Researchers can observe software engineers' usage of LLM-based tools in the field, or study if and how they adopt such tools, their usage patterns, as well as perceived benefits and challenges.
Surveys, interviews, observational studies, or analysis of usage logs can provide insights into how LLMs are integrated into development processes, how they influence decision making, and what factors affect their acceptance and effectiveness. 
Such studies can inform improvements for existing LLM-based tools, motivate the design of novel tools, or derive best practices for LLM-assisted software engineering.
They can also uncover risks or deficiencies of existing tools.

\studytypeparagraph{Example(s)}

\citeauthor{DBLP:journals/pacmse/KhojahM0N24} investigated the use of ChatGPT (GPT-3.5) by professional software engineers in a week-long observational study~\cite{DBLP:journals/pacmse/KhojahM0N24}.
They found that most developers do not use the code generated by ChatGPT directly but instead use the output as a guide to implement their own solutions.
%Furthermore, they recommend that future research investigate the use of ChatGPT in non code-related SE tasks and for training and learning SE concepts.
\citeauthor{DBLP:conf/csee/AzanzaPIG24} conducted a case study that evaluated the impact of introducing LLMs on the onboarding process of new software developers~\cite{DBLP:conf/csee/AzanzaPIG24} (GPT-3).
Their study identified potential in the use of LLMs for onboarding, as it can allow newcomers to seek information on their own, without the need to \enq{bother} senior colleagues.
%However, they also highlight significant privacy concerns with the use of proprietary, third-party LLMs.
Surveys can help researchers to quickly provide an overview of the current perceptions of LLM usage.
For example, \citeauthor{DBLP:conf/icsa/JahicS24} surveyed participants from 15 software companies regarding their practices on LLMs in software engineering~\cite{DBLP:conf/icsa/JahicS24}.
They found that the majority of study participants had already adopted AI for software engineering tasks; most of them used ChatGPT.
Multiple participants cited copyright and privacy issues, as well as inconsistent or low-quality outputs, as barriers to adoption.
Retrospective studies that analyze data generated while developers use LLMs can provide additional insights into human-LLM interactions.
For example, researchers can employ data mining methods to build large-scale conversation datasets, such as the DevGPT dataset introduced by \citeauthor{DBLP:conf/msr/XiaoTHM24}~\cite{DBLP:conf/msr/XiaoTHM24}.
Conversations can then be analyzed using quantitative~\cite{DBLP:conf/msr/RabbiCZI24} and qualitative~\cite{DBLP:conf/msr/MohamedPP24} analysis methods.

\studytypeparagraph{Advantages}

Studying the real-world usage of LLM-based tools allows researchers to understand the state of practice and guide future research directions.
In field studies, researchers can uncover usage patterns, adoption rates, and the influence of contextual factors on usage behavior.
Outside of a controlled study environment, researchers can uncover contextual information about LLM-assisted SE workflows beyond the specific LLMs being evaluated.
This may, for example, help researchers generate hypotheses about how LLMs impact developer productivity, collaboration, and decision-making processes.
In controlled laboratory studies, researchers can study specific phenomena related to LLM usage under carefully regulated, but potentially artificial conditions.
Specifically, they can isolate individual tasks in the software engineering workflow and investigate how LLM-based tools may support task completion.
Furthermore, controlled experiments allow for direct comparisons between different LLM-based tools.
The results can then be used to validate general hypotheses about human-LLM interactions in SE.

\studytypeparagraph{Challenges}

When conducting field studies in real-world environments, researchers have to ensure that their study results are \enq{dependable}~\cite{Sullivan2011-ub} beyond the traditional validity criteria such as internal or construct validity.
The usage environment in a real-world context can often be extremely diverse.
The integration of LLMs can range from specific LLMs based on company policy to the unregulated use of any available LLM. 
Both extremes may influence the adoption of LLM by software engineers, and hence need to be addressed in the study methodology.
In addition, in longitudinal case studies, the timing of the study may have a significant impact on its result, as LLMs and LLM-based tools are rapidly evolving.
Moreover, developers are still learning how to best make use of the new technology, and best practices are still being developed and established.
Furthermore, the predominance of proprietary commercial LLM-based tools in the market poses a significant barrier to research.
Limited access to telemetry data or other usage metrics restricts the ability of researchers to conduct comprehensive analyses of real-world tool usage.
To make study results reliable, researchers must establish that their results are rigorous, for example, by using triangulation to understand and minimize potential biases~\cite{Sullivan2011-ub}.
When it comes to studying LLM usage in controlled laboratory studies, researchers may struggle with the inherent variability of LLM outputs.
Since reproducibility and precision are essential for hypothesis testing, the stochastic nature of LLM responses---where identical prompts may yield different outputs across participants---can complicate the interpretation of experimental results and affect the reliability of study findings.
